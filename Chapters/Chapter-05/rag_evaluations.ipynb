{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://mng.bz/8wdg\" target=\"_blank\">\n",
    "    <img src=\"../../Assets/Images/NewMEAPHeader.png\" alt=\"New MEAP\" style=\"width: 100%;\" />\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 05 - RAG Evaluation: Accuracy, Relevance, Faithfulness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome to chapter 5 of A Simple Introduction to Retrieval Augmented Generation.\n",
    "\n",
    "In this chapter, we will assess the quality of the RAG pipeline we have built in Chapter 3 & 4. We will re-use the [knowledge base](../../Assets/Data/) we created with the Wikipedia article. We will reuse the Retrieval Augmentation and Generation functions we built in Chapter 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the necessary libraries for running this notebook along with their versions can be found in __requirements.txt__ file in the root directory of this repository\n",
    "\n",
    "You should go to the root directory and run the following command to install the libraries\n",
    "\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "This is the recommended method of installing the dependencies\n",
    "\n",
    "___\n",
    "Alternatively, you can run the command from this notebook too. The relative path may vary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../../requriements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Re-Load the RAG Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In chapter 4, we created the generation pipeline. We will bring that here to use it for evaluations.\n",
    "\n",
    "In Chapter 3, we were working on indexing the Wikipedia page for the 2023 cricket world cup. If you recall we had used embeddings from OpenAI to encode the text and used FAISS as the vector index to store the embeddings. We also stored the FAISS index in a local directory. We will use this in the RAG pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: You will need an __OpenAI API Key__ which can be obtained from [OpenAI](https://platform.openai.com/api-keys) to reuse the embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialize the __OpenAI client__, we need to pass the api key. There are many ways of doing it. \n",
    "\n",
    "####  [Option 1] Creating a .env file for storing the API key and using it # Recommended\n",
    "\n",
    "Install the __dotenv__ library\n",
    "\n",
    "_The dotenv library is a popular tool used in various programming languages, including Python and Node.js, to manage environment variables in development and deployment environments. It allows developers to load environment variables from a .env file into their application's environment._\n",
    "\n",
    "- Create a file named .env in the root directory of their project.\n",
    "- Inside the .env file, then define environment variables in the format VARIABLE_NAME=value. \n",
    "\n",
    "e.g.\n",
    "\n",
    "OPENAI_API_KEY=YOUR API KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: .env file found with some environment variables\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "if load_dotenv():\n",
    "    print(\"Success: .env file found with some environment variables\")\n",
    "else:\n",
    "    print(\"Caution: No environment variables found. Please create .env file in the root directory or add environment variables in the .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Option 2] Alternatively, you can set the API key in code. \n",
    "However, this is not recommended since it can leave your key exposed for potential misuse. Uncomment the cell below to use this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-******\" #Imp : Replace with an OpenAI API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also test if the key is valid or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY is set and is valid\n"
     ]
    }
   ],
   "source": [
    "api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "if api_key:\n",
    "    try:\n",
    "        client.models.list()\n",
    "        print(\"OPENAI_API_KEY is set and is valid\")\n",
    "    except openai.APIError as e:\n",
    "        print(f\"OpenAI API returned an API Error: {e}\")\n",
    "        pass\n",
    "    except openai.APIConnectionError as e:\n",
    "        print(f\"Failed to connect to OpenAI API: {e}\")\n",
    "        pass\n",
    "    except openai.RateLimitError as e:\n",
    "        print(f\"OpenAI API request exceeded rate limit: {e}\")\n",
    "        pass\n",
    "\n",
    "else:\n",
    "    print(\"Please set you OpenAI API key as an environment variable OPENAI_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RAG pipeline takes three inputs - \n",
    "1. User Query\n",
    "2. Location of the Vector Index (Knowledge base)\n",
    "3. Index Name\n",
    "\n",
    "And generate an answer along with the retrieved documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAG function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Replace non-breaking space with regular space\n",
    "    text = text.replace('\\xa0', ' ')\n",
    "    \n",
    "    # Remove any HTML tags (if any)\n",
    "    text = re.sub(r'<[^>]+>', '', text)  # Removes HTML tags\n",
    "    \n",
    "    # Remove references in brackets (e.g., [7], [39])\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # Removes references inside square brackets\n",
    "    \n",
    "    # Remove extra spaces and newlines\n",
    "    text = ' '.join(text.split())  # This will remove extra spaces and newline characters\n",
    "    \n",
    "    return text\n",
    "\n",
    "def rag_function(query, db_path, index_name):\n",
    "    embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "    db=FAISS.load_local(folder_path=db_path, index_name=index_name, embeddings=embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "    retrieved_docs = db.similarity_search(query, k=2)\n",
    "\n",
    "    retrieved_context=[clean_text(retrieved_docs[0].page_content + retrieved_docs[1].page_content)]\n",
    "\n",
    "\n",
    "    augmented_prompt=f\"\"\"\n",
    "\n",
    "    Given the context below answer the question.\n",
    "\n",
    "    Question: {query} \n",
    "\n",
    "    Context : {retrieved_context}\n",
    "\n",
    "    Remember to answer only based on the context provided and not from any other source. \n",
    "\n",
    "    If the question cannot be answered based on the provided context, say I donâ€™t know.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    "    )\n",
    "\n",
    "    messages=[(\"human\",augmented_prompt)]\n",
    "\n",
    "    ai_msg = llm.invoke(messages)\n",
    "\n",
    "    response=ai_msg.content\n",
    "\n",
    "    return retrieved_context, response\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try sending our question to this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['The tournament was contested by ten national teams, maintaining the same format used in 2019 . After six weeks of round-robin matches, India , South Africa , Australia , and New Zealand finished as the top four and qualified for the knockout stage. In the knockout stage, India and Australia beat New Zealand and South Africa, respectively, to advance to the final, played on 19 November at the Narendra Modi Stadium in Ahmedabad . Australia won the final by six wickets, winning their sixth Cricket World Cup title.The host India was the first team to qualify for the semi-finals after their 302-run win against Sri Lanka , their seventh successive win in the World Cup. India secured the top place amongst the semi-finalists after they beat South Africa by 243 runs on 5 November at Eden Gardens in Kolkata .'],\n",
       " 'Australia won the world cup.')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_function(query=\"Who won the world cup?\", db_path=\"../../Assets/Data\", index_name=\"CWC_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ask another one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Virat Kohli was named the player of the tournament and also scored the most runs, while Mohammed Shami was the leading wicket-taker. A total of 1,250,307 spectators attended the matches, the highest number in any Cricket World Cup to date. The tournament final set viewership records in India, drawing 518 million viewers, with a peak of 57 million streaming viewers.The ICC announced its team of the tournament on 21 November 2023, with Virat Kohli being named as player of the tournament , and Rohit Sharma as captain of the team.'],\n",
       " 'Virat Kohli was named the player of the tournament and scored the most runs.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_function(query=\"What was Virat Kohli's achievement in the Cup?\",db_path=\"../../Assets/Data\", index_name=\"CWC_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try asking a question which is out of the scope of our knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['(RLQ=window.RLQ||).push(function(){mw.config.set({\"wgHostname\":\"mw-web.codfw.main-85db9df4c9-86vj4\",\"wgBackendResponseTime\":174,\"wgPageParseReport\":{\"limitreport\":{\"cputime\":\"2.102\",\"walltime\":\"2.387\",\"ppvisitednodes\":{\"value\":29880,\"limit\":1000000},\"postexpandincludesize\":{\"value\":547658,\"limit\":2097152},\"templateargumentsize\":{\"value\":113569,\"limit\":2097152},\"expansiondepth\":{\"value\":13,\"limit\":100},\"expensivefunctioncount\":{\"value\":22,\"limit\":500},\"unstrip-depth\":{\"value\":1,\"limit\":20},\"unstrip-size\":{\"value\":312186,\"limit\":5000000},\"entityaccesscount\":{\"value\":1,\"limit\":400},\"timingprofile\":[\"100.00% 1812.691 1 -total\",\" 22.76% 412.523 1 Template:Reflist\",\" 14.91% 270.321 37 Template:Cite_web\",\" 11.46% 207.704 58 Template:Single-innings_cricket_match\",\" 11.12% 201.536 1 Template:2023_CWC_and_2025_ICC_CT_sidebar\",\" 10.94% 198.332 1 Template:Sidebar_with_collapsible_lists\",\" 7.79% 141.132 96 Template:Cr\",\" 7.15% 129Background Host selection'],\n",
       " 'I donâ€™t know.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_function(query=\"What RAG?\",db_path=\"../../Assets/Data\", index_name=\"CWC_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some of the questions, the response may be \"I don't know\". That is when the LLM can't find an answer in the retrieved context. In our augmentation step, we had asked the LLM to do so. But how good is this system? We need to be able to evaluate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RAGAs Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ragas](https://docs.ragas.io/en/stable/) is a framework that helps you evaluate your Retrieval Augmented Generation (RAG) pipelines. It has been developed by the good folks at [exploding gradients](https://github.com/explodinggradients)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look at this evaluation in 2 parts. \n",
    "\n",
    "1. Creation of synthetic test data for evaluation.\n",
    "2. Calculation of evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Creation of Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthetic Data Generation uses LLMs to generate diverse questions and answers from the documents in the knowledge base. LLMs can be prompted to create questions like simple questions, multi-context questions, conditional questions, reasoning questions etc. using the documents from the knowledge base as context.\n",
    "\n",
    "<img src=\"../../Assets/Images/5.1.png\" width=70%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "Fetching pages: 100%|##########| 1/1 [00:00<00:00,  3.25it/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import AsyncHtmlLoader\n",
    "\n",
    "#This is the url of the wikipedia page on the 2023 Cricket World Cup\n",
    "url=\"https://en.wikipedia.org/wiki/2023_Cricket_World_Cup\"\n",
    "\n",
    "#Instantiating the AsyncHtmlLoader\n",
    "loader = AsyncHtmlLoader (url)\n",
    "\n",
    "#Loading the extracted information\n",
    "html_data = loader.load()\n",
    "\n",
    "from langchain_community.document_transformers import Html2TextTransformer\n",
    "\n",
    "#Instantiate the Html2TextTransformer function\n",
    "html2text = Html2TextTransformer()\n",
    "\n",
    "\n",
    "#Call transform_documents\n",
    "html_data_transformed = html2text.transform_documents(html_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings(model=\"text-embedding-3-small\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating personas: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.06s/it]                                           \n",
      "Generating Scenarios: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:07<00:00,  3.67s/it]\n",
      "Generating Samples: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  3.40it/s]\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "dataset = generator.generate_with_langchain_docs(html_data_transformed, testset_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_queries = dataset.to_pandas()['user_input'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_responses=dataset.to_pandas()['reference'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_to_eval=[]\n",
    "\n",
    "for query, reference in zip(sample_queries,expected_responses):\n",
    "    rag_call_response=rag_function(query=query, db_path=\"../../Assets/Data/\", index_name=\"CWC_index\")\n",
    "    relevant_docs=rag_call_response[0]\n",
    "    response=rag_call_response[1]\n",
    "    dataset_to_eval.append(\n",
    "        {\n",
    "            \"user_input\":query,\n",
    "            \"retrieved_contexts\":relevant_docs,\n",
    "            \"response\":response,\n",
    "            \"reference\":reference\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import EvaluationDataset\n",
    "evaluation_dataset = EvaluationDataset.from_list(dataset_to_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:40<00:00,  1.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context_recall': 0.3867, 'faithfulness': 0.8000, 'answer_correctness': 0.5802, 'answer_relevancy': 0.5674, 'factual_correctness': 0.3810}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
    "\n",
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, AnswerCorrectness, ResponseRelevancy\n",
    "\n",
    "result = evaluate(dataset=evaluation_dataset,metrics=[LLMContextRecall(), Faithfulness(), AnswerCorrectness(), ResponseRelevancy(), FactualCorrectness()],llm=evaluator_llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_recall': 0.3867, 'faithfulness': 0.8000, 'answer_correctness': 0.5802, 'answer_relevancy': 0.5674, 'factual_correctness': 0.3810}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "You can interpret the results above. Looks like we are performing well on __faithfulness__ but other metrics are low. How to improve the metrics? We will look at advanced pre-retrieval, retrieval and post retrieval strategies in the next chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../Assets/Images/profile_s.png\" width=100> \n",
    "\n",
    "Hi! I'm Abhinav! I am an entrepreneur and Vice President of Artificial Intelligence at Yarnit. I have spent over 15 years consulting and leadership roles in data science, machine learning and AI. My current focus is in the applied Generative AI domain focussing on solving enterprise needs through contextual intelligence. I'm passionate about AI advancements constantly exploring emerging technologies to push the boundaries and create positive impacts in the world. Letâ€™s build the future, together!\n",
    "\n",
    "[If you haven't already, please subscribe to the MEAP of A Simple Guide to Retrieval Augmented Generation here](https://mng.bz/8wdg)\n",
    "\n",
    "<a href=\"https://mng.bz/8wdg\" target=\"_blank\">\n",
    "    <img src=\"../../Assets/Images/NewMEAPFooter.png\" alt=\"New MEAP\" style=\"width: 100%;\" />\n",
    "</a>\n",
    "\n",
    "#### If you'd like to chat, I'd be very happy to connect\n",
    "\n",
    "[![GitHub followers](https://img.shields.io/badge/Github-000000?style=for-the-badge&logo=github&logoColor=black&color=orange)](https://github.com/abhinav-kimothi)\n",
    "[![LinkedIn](https://img.shields.io/badge/LinkedIn-000000?style=for-the-badge&logo=linkedin&logoColor=orange&color=black)](https://www.linkedin.com/comm/mynetwork/discovery-see-all?usecase=PEOPLE_FOLLOWS&followMember=abhinav-kimothi)\n",
    "[![Medium](https://img.shields.io/badge/Medium-000000?style=for-the-badge&logo=medium&logoColor=black&color=orange)](https://medium.com/@abhinavkimothi)\n",
    "[![Insta](https://img.shields.io/badge/Instagram-000000?style=for-the-badge&logo=instagram&logoColor=orange&color=black)](https://www.instagram.com/akaiworks/)\n",
    "[![Mail](https://img.shields.io/badge/email-000000?style=for-the-badge&logo=gmail&logoColor=black&color=orange)](mailto:abhinav.kimothi.ds@gmail.com)\n",
    "[![X](https://img.shields.io/badge/Follow-000000?style=for-the-badge&logo=X&logoColor=orange&color=black)](https://twitter.com/abhinav_kimothi)\n",
    "[![Linktree](https://img.shields.io/badge/Linktree-000000?style=for-the-badge&logo=linktree&logoColor=black&color=orange)](https://linktr.ee/abhinavkimothi)\n",
    "[![Gumroad](https://img.shields.io/badge/Gumroad-000000?style=for-the-badge&logo=gumroad&logoColor=orange&color=black)](https://abhinavkimothi.gumroad.com/)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ch5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
